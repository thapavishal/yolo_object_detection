{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# matplot uses --->RGB channel\n",
    "# cv2 uses     --->BGR channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading Yolo models(weights and config)\n",
    "net = cv2.dnn.readNet('yolov3.weights','yolov3.cfg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load classes from coco \n",
    "classes = []\n",
    "with open(\"coco.names\", \"r\") as f:\n",
    "    classes = [line.strip() for line in f.readlines()]\n",
    "    #classes = f.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3, 416, 416)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the target image that we want to do the object detection\n",
    "my_img = cv2.imread('D:\\image.jpg')\n",
    "my_img = cv2.resize(my_img,(1280,720))\n",
    "ht, wt, _ = my_img.shape\n",
    "# also the convert the BGR image into RGB image i.e. swapRB = True\n",
    "# input image is in different format\n",
    "# but the darknet or the yolo takes the image in different format\n",
    "# --> so you need to convert your image before feeding into the yolo network\n",
    "blob = cv2.dnn.blobFromImage(my_img, 1/255, (416,416), (0,0,0), swapRB = True, crop = False)\n",
    "blob.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to feeding this blob into your network, we can write\n",
    "# since our saved model is inside the 'net' object\n",
    "net.setInput(blob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we want to get the o/p from the network,for that we need to define the last layer of the NN\n",
    "# this function getUnconnectedOutLayersNames --> is just to get the ouput layers name\n",
    "last_layer = net.getUnconnectedOutLayersNames()\n",
    "# This will get you the names of the last layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to get the output from the last layer then\n",
    "layer_out = net.forward(last_layer)\n",
    "#layer_out[0].shape\n",
    "#layer_out[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes = []\n",
    "confidences = []\n",
    "class_ids = []\n",
    "\n",
    "for output in layer_out:\n",
    "    for detection in output:\n",
    "        score = detection[5:] # probability of each class are coming after 5th element\n",
    "        # to identify that particular element we need to apply numpy argmax method\n",
    "        # it returns the highest value index from the array\n",
    "        class_id = np.argmax(score) \n",
    "        # class_id has given the index of the element, confidence will give the probability of that element\n",
    "        confidence = score[class_id]\n",
    "        if confidence > 0.6:\n",
    "            center_x = int(detection[0]*wt)\n",
    "            center_y = int(detection[1]*ht)\n",
    "            w = int(detection[2]*wt)\n",
    "            h = int(detection[3]*ht)\n",
    "# here the detection will be between o and 1 and to convert that into\n",
    "# normal image size it is multiplied by width and height\n",
    "            \n",
    "# Now since we got the centerx,y and your width, height\n",
    "# we want to figure out the value in the x-dimension and y-dimension\n",
    "            x = int(center_x -w/2)\n",
    "            y = int(center_x -h/2)\n",
    "        \n",
    "            boxes.append([x,y,w,h])\n",
    "            confidences.append((float(confidence)))\n",
    "            class_ids.append(class_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# when we do the object detection, more than one bounding boxes happens,\n",
    "# so we use the non-maximum suppression\n",
    "# to only keep the highest scores boxes\n",
    "#print(len(boxes))\n",
    "indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
    "#indexes\n",
    "font = cv2.FONT_HERSHEY_PLAIN\n",
    "colors = np.random.uniform(0,255,size=(len(boxes),3)) # gives different colored bounding \n",
    "                                                      # for two or more images in same image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for drawing bounding boxes on top of images\n",
    "for i in indexes.flatten(): # flatten --> we need this in a single list\n",
    "    x,y,w,h = boxes[i]  # get x,y,h,w coordinates from boxes\n",
    "    label = str(classes[class_ids[i]]) # in label we want to give the class name \n",
    "    confidence = str(round(confidences[i],2)) # round-off to 2 decimal number\n",
    "    color = colors[i]\n",
    "    \n",
    "    cv2.rectangle(my_img,(x,y), (x+w,y+h),color,2)\n",
    "                #(image, initial coordinates, final coordniates)\n",
    "    cv2.putText(my_img,label +\" \"+confidence,(x,y+20),font,2,(0,0,0),2)\n",
    "    \n",
    "cv2.imshow('img',my_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# once we have the image then we need to convert it into input image that can be fit into yolo frame\n",
    "# first of all we need to resize the image into \n",
    "# we need to normalize it by dividing the pixel value by 255\n",
    "# and the values are also intended to be in RGB order\n",
    "\n",
    "# since our saved model is inside the 'net' object\n",
    "#net.setInput(blob) # this setInput is used to set the input from the blob into the network\n",
    "# we need to define the output layer names \n",
    "# and from net we get the layer names\n",
    "# this function getUnconnectedOutLayersNames --> is just to get the ouput layers name\n",
    "#output_layers_name = net.getUnconnectedOutLayersNames()\n",
    "#layerOutputs = net.forward(output_layers_name)\n",
    "\n",
    "# we need the extract the bounding boxes, confidences and the predicted classes\n",
    "#into different lists\n",
    "#first we inilialize the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
